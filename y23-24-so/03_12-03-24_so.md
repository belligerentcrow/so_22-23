# 3 Lezione -- Sistemi Operativi 

---

1. [Dispositivi di I/O](#dispositivi-di-io)
    1. [Esempio: richiesta di lettura/scrittura su disco](#esempio-richiesta-di-letturascrittura-su-disco)
        1. [DMA](#dma)
        2. [Bus](#bus)
2. [Progettazione di sistemi operativi](#progettazione-di-sistemi-operativi)
    1. [Mainframe/server](#mainframeserver)
    2. 

---

## Dispositivi di I/O 

### Esempio: richiesta di lettura/scrittura su disco

Viene vista dall'SO come una **richiesta "lenta"** --> necessitano dei tempi lunghi. Nel frattempo che questa richiesta viene esaudita, **il processo e' bloccato** dal punto di vista logico perche' non puo' fare cose nel frattempo. --> La CPU esegue nel frattempo esegue il codice del Kernel relativo alla lettura su disco. Tramite il Driver inoltra questa richiesta e viene pilotata verso il controller --> che esegue per conto suo la "fetch". Non posso tornare al processo immediatamente, **restituisco la CPU ad un altro processo** nel frattempo. A quale? Si vedra' nella **coda dei processi pronti**.  
  
Interrupt X --> Ad una procedura Y ad esso associata.  
  
I dati che servono alla CPU saranno nel **buffer interno del controller** --> E l'SO li deve portare nello spazio di indirizzamento del processo che ha richiesto quei dati. Il passaggio dai buffer alla memoria centrale deve essere gestito dall'SO. Passa dalle porte di IO. Questo compito e' del SO. In assenza del meccanismo di Interrupts --> l'SO doveva continuamente controllare se l'operazione fosse finita. (Busy Waiting, usa la CPU per controllare, male! in generale).  
  
#### DMA

[**DMA**](https://en.wikipedia.org/wiki/Direct_memory_access) --> **Direct Memory Access**, trasferisce dati dal buffer controller alla RAM non utilizzando la CPU. Nella fase di avvio della richiesta. In assenza di questa e' il SO che spinge Word per Word da RAM a disco e viceversa. Alleggerisce il compito permettendo di fare altro nel frattempo levando l'onere del trasferimento alla CPU.  
  
Il processo verra' messo quindi messo nella coda dei processi e quando arriva il suo turno sara' ripescato e ripreso da dove finiva la chiamata a sistema.

#### Bus

* PCIexpress (Lo standard per i collegamenti interni) e vari USB per i collegamenti esterni.  

## Progettazione di Sistemi Operativi
  
Raramente vengono creati nuovi SO.  
Categoria e settori diversi hanno diverse esigenze --> ma i SO che abbiamo gia' riescono bene ad adattarsi alle nuove tipologie. Molto modulabili.  
Esempi:  

###  Mainframe/Server

**Mainframe** = Grossi computer destinati a elaborare grandi quantita' di dati e elaborare richieste provenienti dalla rete, transazioni economiche. I server sono comunque calcolatori piu' potenti dei PC ma meno dei mainframe. Sono accomunati dal processare grosse richieste di IO e storage. Accomunabili dai sistemi patch/fetch?. Si utilizzano pesantemente le tecniche di time-sharing per ottimizzare il tempo e massimizzare il throughput. Non e' necessaria la GUI.  

### Personal Computers

Comunque utilizzano il timesharing --> Lanciamo tanti servizi. Multi-programmabile -> equipaggiati con CLI e GUI. Sono sistemi interattivi. A differenza dai Mainframe l'operatore interagisce direttamente con la gui, e sorge la necessita' di un sistema reattivo. Cio' si fa applicando algoritmi di scheduling specifici. Sistemi interattivi --> Algoritmi con tecniche di correlazione/prelazione? L'SO ha quindi bisogno di togliere la CPU al processo se la sta usando troppo. 

### Palmari/Smartphone

Richiedono delle tecniche ad hoc di risparmio batteria.


### Sistemi integrati/embedded

Dispositivi come router, modem, stampanti, "things" --> Hanno concetto di processi e sistemi operativi, anche se piu' rudimentali. Molti di questi usano gli stessi SO dei server: ad esempio Linux. Processi scelti dal creatore/progettista del dispositivo e generalmente non cambiano mai (sono anche sistemi chiusi). Dovrebbero funzionare sempre una volta accessi --> L'utente non va a toccare nulla all'interno o sostituire processi; generalmente e' un sistema prevedibile. (Esempio: microcontrollori)  

### Realtime

Sistemi di elaborazione che pilotano ambiti da multimediale a industriale. Sistemi di monitoraggio o di catene di montaggio --> Questi elaboratori vanno a monitorare situazioni sensori e dispositivi affinche' tutto vada a buon fine. Sistemi di sicurezza e di controllo. La caratteristica critica e' la tempestivita' e il non dover perdere tempo: ci sono delle soglie di tolleranza ma viene data la priorita' a fare l'azione in tempo. Ci sono una serie di restrinzioni nella progettazione di questi sistemi. Ci vogliono sistemi operativi ad hoc pensati e progettati in origine con le tecniche necessarie per farli funzionare in real time. Anche questi sono sistemi chiusi.  

---

## Strutture di sistemi operativi 

Molti sono anche degli ibridi tra piu' design.  

### Struttura monolitica

Sistema piu' "vecchio" ma anche piu' semplice. "Monolitico" e' con accezione negativa. Esempi: primi sistemi unix, msDos. Il codice non e' organizzato (ce lo si poteva permettere nei primi sistemi operativi piu' semplici). Non c'era alcuna protezione ne' memoria virtuale. i processi potevano scrivere dove volevano e l'SO era utile per i processi piu' semplici. No parallelismo no time sharing. Non c'era nessuna separazione --> Spaghetti code.  
Difficilmente era possibile correggere il codice e individuare i bug. Poco gestibile nel tempo. Un gran casino.  

### Struttura a strati / a livelli

Piu' avanzata --> Una caratteristica progettuale. Semplificava la progettazione e la manutenzione. Ogni livello implementa funzionalita' sfruttando le interfacce offerte dal livello inferiore e offrendo a sua volta interfaccia al livello superiore. Ampi e multipli spazi di indirizzamento. Gli strati offrono servizi ai livelli superiori che non si devono preoccupare di implementare quelle cose a sua volta ma li usano: ad esempio, la CPU virtuale. Per il livello di sopra, non si preoccupa come le CPU funzionino ma lavora direttamente dando per garantito il fatto di avere TOT CPUs come gli ha detto il livello che ha implementato la CPU virtuale.  
Il numero di linee di codice di ogni livello e' minore rispetto a un software monolitico e viene meglio la manutenzione. Diamo per scontato che lo strato sottostante funzioni e partendo da questa ipotesi, in maniera induttiva, costruiamo i livelli superiori. Dato per buono il primo livello costruiamo il secondo. Si assume che lo strato sottostante funzioni e si deve solo preoccupare di conoscere le caratteristiche dell'interfaccia.  
L'aspetto negativo e' che: L'ordine dei livelli e in quale livello dovrei mettere un servizio non e' scontato. Posso utilizzare solo i servizi dei livelli che sono sotto. L'isolamento dei livelli della struttura puo' diventare una limitazione.  
Inoltre l'isolamento prevede che uno strato possa parlare solo con il livello immediatamente sottostante a se'. Se deve utilizzare un servizio di diversi livelli sotto, c'e' un overhead in piu' che si paga nel passaggio da livello a livello (nonostante logicamente funzioni).  
Prima era un isolamento che vale solo in termini progettuali: una volta lanciato il sistema operativo un bug in un livello puo' pasticciare tutti i livelli (tutti vanno in modalita' kernel!). Allora i sistemi MULTICS cercano di garantire una separazione forzata dei livelli per fare in modo che un bug di un livello non andasse a incasinare anche gli altri.  
Esempio: **Sistema MULTICS** ad anelli concentrici, che erano supportati e forzati dall'hardware. I vari strati vanno ad utilizzare poteri sempre piu' limitati verso l'esterno, con privilegi sempre minori. (Non bianco e nero tipo user vs kernel ma una scala piu' graduale di privilegi). L'ultimo livello e' l'user mode. E in ogni strato viene definito le aree di memoria che posso toccare. Potenzialmente crea un sistema piu' stabile. Pero', ha una amplificazione del problema di prima. Usare i servizi dello strato sottostante, piu' di una call e' una syscall, con meccanismi simili a quelli della trap.  

### Microkernel

Torniamo a sole due modalita': Kernel e utente. Si creano dei moduli che si occupano di una componente che normalmente sarebbe all'interno del kernel. Come? Idea di semplificare il nucleo principale del microkernel, mantenendo le funzionalita' del kernel in se'. Piu' a basso livello e permettono il sistema a moduli di comunicare e funzionare. Le cose essenziali vengono tenuti all'interno dello zoccolo duro del microkernel; Interrupts, processes, scheduling, inter-process-communication, clock, syscalls. I **moduli vengono esternalizzati**. Hanno il proprio codice e i propri dati e vengono eseguiti in modalita' utente. Ogni modulo ha un obbiettivo ben preciso ed e' separato; ha bisogno di dati e servizi e avviene tramite messaggi. Si traduce tutto in chiamate di sistema. Il "postino" di questi messaggi e' il microkernel stesso.  
* Moduli piu' piccoli, circoscritti, si possono gestire meglio.
* Idea meno limitante dell'idea a strati: il messaggio puo' partire da qualunque processo a qualunque altro processo. Maggiore liberta' e meno vincoli. Comunicazioni piu' dirette: meno salti e meno overhead.  
* Ognuno dei moduli offre interfacce dei propri servizi ad altri, e l'isolamento diventa un valore aggiunto. Un bug in uno dei moduli fara' danni solo al proprio modulo. Modulo Reincarnation: Se uno dei processi fa qualcosa di strano viene ammazzato (killed) e ripristinato.  

### Struttura a Moduli

Tutte le componenti del sistema linux sono isolate in moduli (talvolta interscambiabili). Tutto tranne lo zoccolo duro del Kernel e' implementato in termine di moduli. All'avvio viene caricato sulla ram un blob binario del kernel che non prevede moduli ma che carica lui moduli a sua richiesta (Anche a run-time!). In che senso carico un modulo? All'occorrenza li metto ALL'INTERNO del Kernel. Ne diventano parte e vengono anche eseguiti in modalita' kernel. Vengono caricati su richiesta.  
Una differenza col microkernel e' che quando un modulo viene caricato in memoria non gira come processo utente. Questo e' una delle critiche che viene fatta --> "E' monolitico", ma non proprio. Ogni modulo nel sistema Linux e' un oggetto in termini di OOP, implementa una serie di servizi. E' progettato in OOP. Se c'e' un bug in un modulo puo' essere un problema, eppure funziona e Linux e' considerato uno dei migliori. Open Source: e' sotto gli occhi di tutti e continuamente revisionato. Rimane il rischio di caricare moduli e driver strani e esterni o non supportati. Di solito i Driver aperti Ndivia sono risultato di reverse engineering della comunita'.  
Un modulo ha anche possibilita' di chiamare un altro modulo ma rispettando la sua interfaccia. Ma sono chiamate da pari a pari (da kernel a kernel), non ci sono messaggi o overhead o priorita' diverse. Dal punto di vista dell'overhead, ce n'e' il minimo che posso avere.  
Anche Mac offre i moduli di Linux (ibrido). Il sistema Linux e' un sistema a moduli. Ma anche Linux sta mutuando alcune idee del microkernel.  

### Macchine Virtuali

Il concetto di VM e' una virtualizzazione della macchina stessa --> Paragonabile a un calcolatore classico. Creare una astrazione totale --> Hardware virtuale dove fare girare software. Proprio perche' e' virtuale ne posso creare piu' di uno. Concretamente posso ottenere un ambiente con il proprio SO, e sull'hardware fisico posso sfruttare le capacita' per mettere diverse istanze della macchina virtuale. Posso eseguire tutto quello che potrei eseguire su una macchina reale: quindi un sistema operativo, che offre servizi ad altre applicazioni.  
L'host si dota di un Hypervisor che offre astrazioni (posso avere macchine virtuali di diversi sistemi operativi). Posso giocare con hardware simulato virtuale ed eseguire software all'interno delle scatole. Puo' essere una buona idea per testare sistemi operativi, per avere a disposizione sistemi operativi diversi per developing sistemi a multipiattaforma; i danni sono circoscritti all'interno della macchina virtuale. Idea di isolamento a macchine.  
Docker --> Idea di isolare una serie di applicazioni all'interno di dockers. Una sorta di virtualizzazione slim.  
* **Hypervisor 1**
    * Gira direttamente sull'hardware. Offre la possibilita' di instanziare macchine virtuali. Implementa il paradigma delle macchine virtuali sull'hardware direttamente. Non c'e' un sistema operativo sottostante. In teoria non prevede applicazioni a fianco delle macchine virtuali.  (KVM -- e' un modulo del kernel di linux che lo trasforma in un hypervisor di tipo 1)
* **Hypervisor 2**
    * C'e' un Host: puo' essere windows o simili. Gira in modalita' utente ed e' una applicazione ma hanno bisogno di interagire con il SO; mettono un piede dentro il kernel tramite drivers.  
    E sul sistema operativo oltre alla VM posso usare le mie altre applicazioni, come anche posso usare le applicazioni in parallelo sulle macchine virtuali.  
  
Nella virtualizzazione il codice viene eseguito in maniera nativa sulla CPU Host. Vengono virtualizzate le periferiche di IO. Li' ci puo' essere un overhead. La CPU in realta' non viene virtualizzata --> Le nuove CPU hanno una modalita' dedicata che favorisce e velocizza la virtualizzazione.  
  
### Simulazione 

La simulazione e' diversa --> Simile all'interpretazione. I sistemi di simulazione riescono a simulare un software antico su un hardware nuovo come se stesse girando su una macchina vecchia (Esempio: Retrogaming)  

### Para virtualizzazione

I controllers di rete non sono modelli standard ma "marca hypervisors" ??? Dispositivo speciale che necessita di drivers ad hoc che una volta instatllato fanno installare in maniera diretta questo tipo di controllers. Se utilizzano dispositivi paravirtualizzati sara' piu' efficiente. Installando il Driver sto "informando" il sistema operativo ospitato che non e' un vero dispositivo. Si cede e si adatta l'ospitato a usare driver effettivi e scegliere ??????? OK! Prestazioni Migliori