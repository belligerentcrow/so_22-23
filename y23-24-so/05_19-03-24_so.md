# 5 Lezione -- Sistemi Operativi 

---

<!-- TOC -->
- [Stato dei processi](#stato-dei-processi)
    - [Coda dei processi pronti](#coda-dei-processi-pronti)
- [Thread](#thread)
    - [Web Browser](#web-browser)
    - [Word Processor](#word-processor)
    - [Web Server](#web-server)
- [Thread pt.2](#thread-pt2)
    - [Operazioni legate ai threads](#operazioni-legate-ai-threads)
- [Programmazione multicore](#programmazione-multicore)
    - [Thread a livello utente](#thread-a-livello-utente)
        - [Modello a thread kernel (1-a-1)](#modello-a-thread-kernel-1-a-1)
        - [Modello dei thread livello utente (1-a-molti)](#modello-dei-thread-livello-utente-1-a-molti)
<!-- /TOC -->


---
note: 

zzzzzzzzzzzzzzzzzzzzz
2+2=10 chiaro e lapalissiano 

---

## Stato dei processi 

--> Tabella dei processi, Process Control Block 
* Idealmente ad ogni processo dedico una porzione di RAM e nel PCB ci sono messi gli indirizzi di memoria dove i dati del programma in questione sono messi
* Questo controllo e' fatto dall'MMU = memory management unit, dall'hardware stesso. si occupa di stabilire che il processo non sta andando oltre il proprio campo di memoria.  
* I PCB --> In coda doppiamente linkate (circolari) dove lo scheduler ne va a pigliare uno 

1) L'hardware si occupa di salvare PC e PSW (i primi a venire "sporcati" se cambio programma)(PSW --> contiene lo stato della CPU e le flags dei passaggi)  
2) Interrupt Syscall --> si arriva ad essa (ovvero viene assegnata alla CPU) tramite un salto, e la CPU deve commutare in modalita' kernel. Nell'indirizzo di memoria 1 c'e' la tabella dei processi che associa gli interrupts alle procedure. I primi valori nei registri pero' deve salvarli cosi' come erano nei registri da qualche parte: nella ram all'indirizzo putnato dalla PCB 
3) Routine associata all'interrupt.  
4) Il lato software deve fare in modo di tornare al processo interrotto dall'interrupt. --> 

### Coda dei processi pronti 

Esistono molte code dei processi bloccati / di attesa; gestiscono sottoinsiemi di processi bloccati (per varie ragioni).  
Esiste una coda per ogni controller --> e code "software" per gestire attese software.  
Le code semplificano i passaggi dei PCB.  
Quando arriva l'evento, e' semplice capire quale processo verra' "svegliato" per primo.   

## Thread  

Abbiamo definito un processo come un **flusso** di esecuzione. C'e' lo spazio di memoria del processo dov'e' il programma, e i suoi dati. L'idea dei thread e' che non abbiamo per forza un solo flusso di esecuzione all'interno di un processo. Ci possono essere piu' flussi di esecuzione (in maniera da ottenere parallelismo in uno stesso processo). Lavorano all'interno dello stesso contenitore/processo e condividono le risorse. Devono anche riuscire a non interferire l'uno con l'altro. Si parla quindi di **programmazione multi-thread**. E' un modello di programmazione che richiede l'uso di accorgimenti (possono sorgere problemi che dobbiamo sistemare). Non e' assolutamente necessario ma e' una ottimizzazione. I thread potenzialmente danno buone caratteristiche alle nostre applicazioni. Quasi tutte le nostre applicazioni sono multi-thread --> Vantaggi.  

### Web Browser
  
Esempio: tre tabs di un web browser. L'idea e' di creare tre thread e di assegnare ad ognuno uno dei task/tab. Creiamo un task per ogni tab/finestra e ogni flusso si occupa di gestire il codice per quel sito. In realta' e' piu' complesso. Prima: un sito alla volta. Pero' e' peggiore in termini di prestazione (tempi morti). E all'interno di un "sito" si possono individuare una serie di sottotasks. --> Ha bisogno di una CPU, ma la CPU fa molte molte cose. Serve quindi parallelismo ma nell'ambito dello stesso processo.   

### Word Processor 
  
Necessita' di gestire diversi tasks.  
--> Qualunque applicazione abbia una GUI ha bisogno di un flusso di esecuzione tutto suo per garantire la interattivita'.  
--> Controllo ortografico  
--> Salvataggio del documento  
Alcuni processi possiamo accettare che si blocchino rispetto ad altri  

### Web Server

Deve elaborare le richieste che gli arrivano. --> Se ne potesse gestire piu' contemporaneamente sarebbe una buona cosa. Dovrebbe essere capace di massimizzare le risorse che gli arrivano ogni minuto.  
Idea: avere 1 thread principale che gestisce la cosa delle richieste. Crea all'occorrenza nuovi thread che si occupando delle sottorichieste. Cosi' posso avere richieste gestite in parallelo o pseudoparallelismo che sono indipendenti.  
Un thread viene creato sotto richiesta di un altro thread.  
Se c'e' una richiesta che prevede di leggere uno o piu' file da disco, questo non influisce sugli altri threads.  
Questo massimizza il numero di richieste. Anche se ci fosse una sola CPU questa viene ripartita ai vari thread e il blocco di un thread non blocca dal punto di vista logica gli altri thread. I thread sono indipendenti gli uni dagli altri.   
Ad ogni thread assegno un task. Di base la programmazione multi-processo e' piu' pesante della multithread.  

---

## Thread pt.2 
  
Un thread e' caratterizzato da PC, registri, stack, **stato**, ma condivide tutto il resto; non c'e' protezione di memoria  
Scheduling dei thread.  
Il cambio di contesto e' piu' veloce. Il cambiamento di stato dei thread e' come quello dei processi: un thread puo' essere pronto, entrare nello stato di running quando viene selezionato per essere schedulato, e le dinamiche sono le stesse. Gli stack indipendenti sono uno dei tratti caratteristici e desiderabili del modello a thread.  
Cosi' quando salvo il documento non si freeza l'interfaccia GUI.  
**Condividono il codice**, i dati, e i files.
Qualunque processo --> thread. il principale aziona il main. Puo' creare suoi pari: multiflussi. Ognuno si occupa di qualcosa.  
  
### Operazioni legate ai threads 

```thread_create``` -->   Crea un thread. Il thread iniziale (che si trova in qualunque thread che istanzio) puo' in qualunque momento usarla. Il thread iniziale dovrebbe essere quello che esegue il main. Bisogna indicare qual e' il codice che dovra' eseguire il thread creato. 
```thread_exit``` -->  Equivalente della exit dei processi nel contesto dei threads. Ad un certo punto il thread puo' terminare spontaneamente. Un processo rimane attivo fino a quando c'e' almeno un thread al suo interno. Quando anche l'ultimo thread ha terminato quello che ha fatto allora il processo terminerebbe (di solito).  
```thread_join```  -->  Una sorta di wait. Uno scenario di processo: il thread principale crea i processi poi aspetta che i threads abbiano finito per ripulire tutto e chiudere. Una sorta di maniera in cui un thread aspetta un altro thread e lo aspetta. Un thread si sincronizza con la fine di un altro thread
```thread_yield``` -->  Una operazione primitiva che puo' essere evocata dai thread stessi e che cede il contenuto della CPU. Se il thread A di sua spontanea volonta' chiama la Yield, allora dichiara di cedere la CPU. In assenza di prelazione e' fondamentale. Se non ci fosse la CPU rischierebbe di essere monopolizzata. Non c'e' sempre la occasione di usare questa operazione anche perche' complica il modello, ma all'inizio era necessaria. In certi contesti ancora si usa.  

## Programmazione multicore
  
I thread permettono una migliore scalabilita' con core con hyperthreading e sistemi multicore.  
Con un sistema multicore abbiamo parallelismo assoluto perche' ogni core si occupa di qualcosa contemporaneamente.  
  
Sfruttare un livello multithread implica separazione dei tasks e programmare con un certo discrimine  
Bisogna **individuare i tasks**; che siano equiparabili tra di loro e che siano abbastanza grandi da giustificare il costo della creazione del thread. Esempio: anche un algoritmo di ordinamento e' possibile ordinarlo in diverse sottotasks. 
Sfruttiamo la capacita' dell'hardware, affidando un compito a un core e un compito ad un altro thread per poter svolgere un programma in pochissimo tempo sfruttando le risorse disponibili. A parita' di algoritmi si accelera l'algoritmo stesso.  
Alcuni thread invece devono lavorare su strutture dati condivise: alcune anche in tempo reale. Ci sono strutture dati personali (vettori di appoggio) ma poi ci sara' una coda condivisa da cui i thread possono attingere con cui scambiarsi informazioni. La struttura dati intermedia diventa di entrambi e viene individuata come struttura dati condivisa.  
Non c'e' un ordine prestabilito --> dobbiamo fare in modo che il codice funzioni comunque  
Problema delle **race conditions**  

* **bilanciamento dei dati**, **suddivisione dei dati**, **dipendenze dei dati**
  
Possono esserci dipendenze logiche ma non si fanno busy waiting --> si fa addormentare il thread e si sfrutta la ```thread_join```  

### Thread a livello utente 

#### Modello a thread kernel (1-a-1)
Modi in cui si puo' implementare il livello a thread. **Modello a thread kernel** o **modello 1-a-1**. Il sistema operativo e' conscio dei thread e li gestisce lui di prima persona. E' come succede la maggior parte delle volte.  
Un task viene assegnato a un thread Kernel --> thread riconosciuti e gestiti dal Kernel. La thread create etc sono chiamate di sistema perche' vengono gestite dall'SO.  
Il kernel li conosce e sa quali thread ci sono all'interno dei processi.  
Per ogni task assegno un thread Kernel. La tabella dei threads e' nel kernel.  

#### Modello dei thread livello utente (1-a-molti)
Piu' economico, ma ha controindicazioni.  
Il primo modello proposto. La tabella dei threads e' gestita all'interno del processo singolo. Si mappano i thread tasks dell'applicazione su un solo thread kernel.  
Il sistema operativo vede un unico flusso e non gestisce i threads. Non ha idea di cosa sia la thread create, thread join, etc. La gestione delle tre threads viene arrangiata ed eseguita in modalita' utente. C'e' una gestione in modalita' utente. La condivisione della CPU viene arrangiata e gestita nello spazio del processo. Al processo il kernel offre nella timeline della CPU dei lassi di tempo. L'idea e' che il sistema di gestione interna dei thread si occupa di suddividere la gestione dei thread interni nei lassi di tempo che il SO da' alla CPU. Il "subaffitto" viene gestito all'interno della applicazione ed e' compito del programmatore della applicazione. Questo viene fatto usando delle librerie di gestione dei thread utente. Un sistema di runtime che si occupa di implementare i thread all'interno del processo. I threads utente saranno noti solo all'ambiente di runtime --> ci sara' una tabella di runtime che prima era nello spazio del kernel. 
E' una forma di timesharing --> grazie alla libreria runtime. Non sono operazioni di kernel perche' il kernel non ne sa niente di threads. Invoca una routine della libreria runtime. Se un thread chiama la sua thread_exit allora il sistema runtime della libreria lo fa esplodere  
Come fa il controllo a passare da thread 1 a thred 2? E' fondamentale che i thread collaborino usando la **thread_yield**. E' l'unico modo con cui possiamo lavorare cosi'. Il codice dei thread 1 a molti e' scritto per essere collaborativo. 
  
Prevede comunque un cambio di contesto ma il passaggio 1-1 prevede anche la commutazione a modalita' kernel mentre il modello dei thread 1-a-molti no perche' gira tutto in modalita' utente. Quindi l'1-a-molti ha meno overhead. Salva e ripristina tutto dentro il contenitore del processo (non passa in modalita' kernel.)   
Una differenza importante e' legata alle operazioni bloccanti. Cosi' le chiamate bloccanti del modello a processo utente si blocca TUTTO il processo. PROBLEMA. Ci sono modi per sistemare cio' (alcune operazioni di IO che normalmente sono bloccanti vengono eseguite con una "SELECT" che predice se una syscall e' bloccante o meno. Se e' bloccante non la fa perche' sa che bloccherebbe tutto quanto. Se e' bloccante invece il thread 1 non progredisce quindi fa una yield. invece di bloccarsi, fa una thread_yield. Loop collaborativo dove invece di aspettare ad un certo punto un altro processo fara' la yield a lui 