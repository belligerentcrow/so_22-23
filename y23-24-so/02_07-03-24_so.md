# 2 Lezione - Sistemi Operativi

* Recap Architettura 

---

# Indice
1. [Ciclo di Fetch-Decode-Execute](#ciclo-di-fetch---decode---execute)
2. [Syscalls](#syscall)
3. [Interrupts](#interrupt-hardware)
4. [Processori](#processori)
    1. [Multi-threading](#multi-threading)
    2. [Multi-core](#multi-core)
        1. [Differenza multicore multicpu](#differenza-multi-cpu-e-multi-core)
    3. [GPU](#gpu)
5. [Memorie](#memorie)
    1. [Registri](#1---registri)
    2. [Cache](#2---cache-della-cpu)
    3. [Memoria Centrale](#3---memoria-centrale)
    4. [Disco Elettronico](#4---disco-elettronico)
    5. [Disco Elettromagnetico](#5---disco-elettromagnetico)
    6. [Notazione](#notazione)
6. [Dispositivi IO](#dispositivi-di-io)


---

## Ciclo di **Fetch - Decode - Execute** 
    * Anche se adesso le CPU sono progettate in maniera molto piu' complicata, utilizzando **PIPELINES**
    * Le pipelines lavorano delle fasi in parallelo facendo in modo che tutto vada piu' veloce
    * Un **throughput** (istruzioni potenzialmente lavorabili) --> Migliora con le pipelines di un fattore 3
    * Funziona nel momento in cui il codice viene eseguito in maniera **sequenziale**. 
    * A volte ha bisogno di buttare dei pezzi -> per gli if per esempio
        * Sono cose che di solito vengono lavorate in Hardware
        * Ma il SO ha l'onere di sapere come funziona l'Hardware
    * Pipelines ottimizzate -> per operazioni di Execute 
        * Con molte fetch units: Le info vengono inserite in un **Buffer** --> 
    * Se le istruzioni sono sequenziali --> A volte possono essere eseguite in maniera non sequenziale
        * non sempre porta a problemi; solamente quando alcune istruzioni dipendono le prime dalle seconde
    * In quel caso le pipelines riordinano l'ordine
        * Tutto questo e' spesso gestito tutto in Hardware, solo alcune volte soluzioni softwares possono aiutare questa situazione
* **PSW -> Collezione di Flag** con vari scopi 
    * Ad esempio -> Modalita' di esecuzione della CPU (Kernel mode vs User mode)
    * Altro : istruzione di ```compare``` --> Il risultato di confronto viene depositato qui (Questi particolari bit non sono protetti o riservati)

Problema = la user mode non dovrebbe essere in grado di cambiare la flag di modalita' di esecuzione
    * La Kernel mode puo' fare il downgrade, ma non puo' avvenire il contrario

---

## Syscall

Due processi utente, P1 e P2, e un processo kernel K; P1 o P2 puo' aver bisogno di chiamare K. <br>
Il meccanismo e' gestito attraverso la operazione **trap** --> Cosa innesca questa istruzione? <br>

Di per se' e' una **chiamata a una procedura** --> bisogna salvare da qualche parte il Program Counter e la PSW --> vengono salvati nello **STACK** del processo

1. Viene fatto il **push() del PC e della PSW** --> Ovvero lo stato della CPU in quel momento 
2. Viene commutata la **modalita' Utente alla modalita' Kernel**
3. Viene effettuato un **salto al codice del Kernel**

* Ogni syscall e' identificata da un codice --> un **ID univoco**. 
    * Il meccanismo di salto --> Salta sempre a una **procedura convenzionale del Kernel**
    * La maggior parte delle syscall hanno bisogno di usare lo stack (del Kernel) e i registri generici (che quindi devono essere salvati)

Quando e' finito, faccio una sorta di **return da una syscall**
Esegue in maniera controllata pezzi di codice del kernel
1. Quando **ritorna** la CPU torna ad essere in **modalita' utente**
2. Le varie chiamate di sistema non posso chiamarle sempre quando voglio: Se faccio una open su un file NON di mia proprieta' NON posso leggerlo. Vengono **implementati diversi controlli** dentro la syscall se il chiamante puo' effettivamente effettuare la chiamata senza destare errori. 

Molte delle syscalls hanno bisogno di **accedere a strutture dati** interne del kernel<br>
**Strutture dati cruciali - interne - protette**<br>
Tra le operazioni inibite alla modalita' utente ci sono quelle che interagiscono con la scheda di rete, la scheda grafica, etc. Cose che non dovrebbero essere toccate dalla <br><br>
**Tabella dei processi** --> la generica voce di essa contiene delle informazioni riguardo a un processo<br>
Quando il processo non e' in esecuzione i valori dei suoi registri vengono salvati (PCB, Process Control Block)<br>

---

## **Interrupt Hardware** 
Sono degli eventi **asincroni** che vengono scatenati da alcune condizioni<br>
Scatenano una **routine** rilevante l'interrupt<br>
Per ogni interrupt notificato **prevede una procedura**<br>
Esiste una tabella degli interrupt che prevede di individuale (nel codice kernel) una procedura per ogni interrupt --> Numerazione associata<br>
Nella architettura x86 --> Si trova all'indirizzo fisico 0 assoluto<br>
1. Gestore dei control (se una richiesta viene completata, l'evento viene comunicato alla CPU tramite una interrupt)
2. Orologio --> Clock interrupt periodico
3. Eventi eccezionali e fatali (Errori, situazioni non previste, eccezioni)

Il software eseguito dalla CPU in modalita' **Kernel** puo' **decidere di disabilitare gli interrupts** (viene accodato e non perso) --> Non e' consigliabile farlo spesso. Molto delicato e bisogna farlo poco spesso. <br>
Il software --> potrebbe decidere di disabilitare gli interrupts all'inizio della syscalls e abilitarli alla fine della syscalls<br>
Alla fine vengono ripristinati i valori dei vari registri e viene commutata anche la modalita' di esecuzione<br>
Puo' anche avvenire che il kernel interrompa la esecuzione del kernel stesso. Non cambia solo la modalita'<br>

## Processori

### Multi-threading 
E' una sorta di **parallelismo finto**: un trucco grazie al quale, avendo una unita' di elaborazione e il set di registri. --> Quando non li sto utilizando metto nei registri i valori di alcuni processi? <br>
L'idea e' che la CPU puo' commutare la sua attenzione da un processo all'altro in maniera molto veloce <br>
Tempi morti --> in cui la CPU non fa niente legata ad eventi ordinari che fanno perdere un poco di tempo.<br>
Ad esempio, codice di +1 --> Se devo fare due fetch ha un costo: devo mettere indirizzi delle locazioni di memoria --> corrisponde ad un certo numero di cicli di una CPU che andrebbero persi;<br>
L'idea e' che invece di lasciare la CPU a non fare niente aspettando di prelevare l'informazione di un contesto, intanto lavora sul secondo contesto<br>
Non e' un vero e proprio parallelismo, in un singolo istante lavoro solo su un processo, ma l'alternanza fa in modo di velocizzare i tempi. Sono tempi rapidissimi gestiti in hardware<br>
Migliora la resa del 20-30% -- Circa dall'Intel I7 in poi<br>
Timesharing e Multi-threading non sono mutualmente esclusivi e possono essere usati assieme. Sono due cose diverse <br>

Posso caricare due contesti su una stessa CPU --> IMPARENTATI e lavorare sullo stesso spazio di indirizzamento. Affinche' la CPU possa passare VELOCEMENTE dall'uno all'altro nei tempi morti. I due flussi devono lavorare allo stesso processo<br>

### Multi-core

Aumentare il numero di CPU nel computer. Posso aumerntare la capacita' di esecuzione del sistema andando a condividere delle risorse (Periferiche di input-output, memoria esterna, ram, dischi)<br>
Si **abbattono anche i costi**: posso elaborare piu' dati a costi piu' bassi<br>
Posso creare anche processi collaboranti (vero parallelismo e scambio tra dati fra loro)<br>
Per esempio con due CPUs --> e un algoritmo ottimizzato per agire su piu' CPUs, viene meglio, sfruttando il fatto che la memoria sia condivisa<br>
Altri motivi per il multicore: invece di aumentare la frequenza di elaborazione (si puo' fare solo fino a un certo punto per motivi fisici come surriscaldamento), si usano pipelines o si aggiungono core!<br>

#### Differenza multi-cpu e multi-core
 
Differenza ingegneristica = sui multicore sono nello stesso package e la comunicazione e' piu' veloce, si riduce il consumo di energia e la dispersione di calore; nella multi-CPU sono due package di due CPU distinte <br>
**Dal punto di vista software non cambia**

### GPU

Una scheda dedicata con multielaborazione particolare; piu' spinta e veloce (centinaia e migliaia di core ma particolari e specifici); Sono fatti per fare tanti piccoli calcoli<br>
Machine learning, blockchaining mine, gaming --> usate da un processo, che usa una serie di suoi cores<br>

---

## Memorie 

Tutti i dispositivi hanno dei piccoli buffers/cache implementati in dei controller ()

### 1 - Registri<br> 
Vanno allo stesso ritmo della CPU. **Volatile e molto veloce e molto piccola.**

### 2 - Cache della CPU
Implementato a vari livelli : sia hardware che software. Questa e' la cache della CPU.<br>
Si frappone tra la CPU e la memoria centrale. <br>
Gli algoritmi di gestione della cache--> Architettura (Cosa usare e cosa no)<br>
E' l'hardware che determina se c'e' un **Cache Hit** o un **Cache Miss**. Dopo la Cache Miss si mette il dato nella cache. Ottimizza l'accesso alla memoria.<br>
Puo' essere **condivisa o dedicata**<br>
Se la cache e' condivisa tra i core allora certi meccanismi sono semplificati (tutte le richieste passano da qui) puo' rappresentare un collo di bottiglia e creare stallo ma ha anche dei vantaggi.<br>
La cache dedicata e' piu' piccola ma non ha concorrenza, ma ci sono complicazioni. <br>
**Update** dei valori in una cache che non avviene in un'altra cache!<br>
**Rischio che i dati non siano coerenti**. Bisogna controllare per queste incoerenze se la cache e' dedicata<br>

### 3 - Memoria centrale 
La RAM. tra essa e i dischi va nello stesso modo in cui Cache e Ram. Anche questa e' memoria volatile. Il SO sfrutta la RAM a mo' di cache quando non e' occupata dai processi. 

### 4 - Disco elettronico
Memoria **NON volatile**. Piu' simile a un banco di RAM con la differenza che non sono volatili. I tempi di accesso sono piu' veloci e la localizzazione delle informazioni e' **costante**. Non c'e' un tempo di rotazione. Ma la **scrittura e' piu' critica!** Una data informazione per essere scritta deve essere cancellata, e ogni area puo' solo essere cancellata un tot di volte.<br>

### 5 - Disco elettromagnetico 
Per ogni superficie si legge e scrive sulla superficie un pacchetto di dati. Si usa una tripletta di **coordinate cilindriche** che identificano un punto del cilindro che e' il disco. Quindi identifico il disco (livello) che serve, lo spicchio, e la distanza dal perno dove e' locata la informazione. <br>
Le letture e le scritture avvengono per blocchi e si **leggono interi pacchetti** e la dimensione dipende da come l'hardware e' progettato.<br>
**Tempo di lettura: Non costante.** Il SO fa trucchi per ottimizzare.<br>
Di solito vengono viste comunque in maniera lineare dal SO (mappatura, anche se le coordinate sono 3)<br>

---

### Notazione 
**Kb/Mb/Gb** (Potenze di 10)(Notazione conveniente in ambito commerciale) VS  **KiB, MiB, GiB** (Potenze di 2)(meno ambiguo)(per la RAM e nel corso si usa questo)

---

## Dispositivi di I.O.

* Disco Serial-ATA => Collegato a un **Controller**
    * dispositivo che ha il compito di gestire uno o piu' dischi. In mezzo tra la scheda madre e il dispositivo in se'
    * E' un piccolo calcolatore!
    * Ogni controller ha una serie di porte di IO (registri) che il software puo' leggere e scrivere
    * Il disco deve essere controllato in tempo reale (controlli, monitoraggi) ma la CPU ha anche altro da fare e gestisce anche interrupts. Avendo una piccola CPU dedicata aiuta per questo. Discorso delle interfacce.
    
    SO <==> CTRL <==> DISPOSITIVI

    Tutti i dispositivi dischi Serial-ATA utilizzano lo stesso dialetto (comunicano con il controller)
    Istruzioni semplici e a basso livello (accendi motore, posiziona testina, controlla posizione testina etc.)
    Questo standard di riferimento --> aiuta per la **compatibilita''**. quindi costano anche meno.<br>
    Il linguaggio usato da questi controller non e' standard --> cambia da controller a controller. E non e' un problema. Ogni progettista di controller puo' decidere il proprio --> Questo vale nella interfaccia tra SO e Controller. <br>
    Qui arrivano i **DRIVERS**. <br>
    Si innestano nell'SO e offrono i propri servizi al SO e funzionano da traduttori. <br>
    Conoscendo la lingua dei controllers e del SO si puo' scrivere un driver. <br>
    Linux ha al suo interno dei drivers per certi dispositivi.<br>
    Il driver entrando a far parte del Kernel ne diventa proprio parte e **deve essere eseguito in modalita' Kernel**. Il problema e' che il driver e' scritto dal produttore del controller e quindi del dispositivo IO... se economizzano sul driver allora ci sono bug importanti che girano in modalita' kernel!<br>
    Se fosse malizioso puo' fare qualunque cosa anche nel SO!<br>
    Per eseguire lettura e scrittura sui registri del controller serve la kernel mode; ma lo stesso meccanismo puo' essere fatto tramite la **mappatura dei registri di IO sulla memoria centrale**.<br>
    Fare corrispondere ad un indirizzo di memoria -> una porta di IO. <br>
    Allora il **SO in modalita' Kernel mappa le porte sulla propria memoria** perche' la mappatura e' una operazione privilegiata --> predispone il driver, lo mette nel processo utente --> Quindi non potra' pasticciare nella memoria ne' dialogare con gli altri controllers. Questo ha degli effetti negativi ma si possono aggirare.<br>
    Quindi il codice del driver non avra' bisogno di essere eseguito in modalita' kernel per eseguire READ/WRITE.<br>


    